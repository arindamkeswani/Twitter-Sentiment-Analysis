{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment Analysis (Training)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq5q+cpIEOirJ5Buq3JgbX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LmlbsCz30ik"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBzKWJj4TnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6918f59f-6958-4721-a922-21c3ea548129"
      },
      "source": [
        "'''\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nfrom pydrive.auth import GoogleAuth\\nfrom pydrive.drive import GoogleDrive\\nfrom google.colab import auth\\nfrom oauth2client.client import GoogleCredentials\\n\\nauth.authenticate_user()\\ngauth = GoogleAuth()\\ngauth.credentials = GoogleCredentials.get_application_default()\\ndrive = GoogleDrive(gauth)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrBuTKmcE5Hf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a02af3d4-b7dc-4172-f26b-c357a0b1cb61"
      },
      "source": [
        "!pip install PyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (47.3.1)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbJfsW2eG79N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "280c10ea-29e5-4f6a-eb0a-2c71d749326f"
      },
      "source": [
        "train_path='/content/drive/My Drive/Datasets/Twitter sentiment analysis dataset/train.txt'\n",
        "test_path='/content/drive/My Drive/Datasets/Twitter sentiment analysis dataset/test_samples.txt'\n",
        "#print(train)\n",
        "\n",
        "import pandas as pd\n",
        "#test=open('/content/drive/My Drive/Datasets/Twitter sentiment analysis dataset/test_samples.txt', encoding='utf-8').read()\n",
        "#train=open('/content/drive/My Drive/Datasets/Twitter sentiment analysis dataset/train.txt', encoding='utf-8').read()\n",
        "\n",
        "train=pd.read_csv(train_path)\n",
        "train=pd.DataFrame(data= train)\n",
        "train.to_csv('train.csv', header=True, index=False, encoding='utf-8')\n",
        "#print(train.columns)\n",
        "print(train)\n",
        "\n",
        "#pd.to_csv(test_path)\n",
        "test=pd.read_csv(test_path)\n",
        "test=pd.DataFrame(data= test)\n",
        "test.to_csv('test.csv', header=True, index=False, encoding='utf-8')\n",
        "#print(test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 tweet_id  ...                                         tweet_text\n",
            "0      264183816548130816  ...  Gas by my house hit $3.39!!!! I\\u2019m going t...\n",
            "1      263405084770172928  ...  Theo Walcott is still shit\\u002c watch Rafa an...\n",
            "2      262163168678248449  ...  its not that I\\u2019m a GSP fan\\u002c i just h...\n",
            "3      264249301910310912  ...  Iranian general says Israel\\u2019s Iron Dome c...\n",
            "4      262682041215234048  ...  Tehran\\u002c Mon Amour: Obama Tried to Establi...\n",
            "...                   ...  ...                                                ...\n",
            "21460  522949024132112384  ...  the day after newark ill be able to say \"\"i me...\n",
            "21461  522372593312350209  ...  FEC hold farewell session for seven ministers ...\n",
            "21462  522515200592052224  ...  Luca Di Montezemolo (who's last day was Monday...\n",
            "21463  523089087155437568  ...  Coffee is pretty much the answer to all questi...\n",
            "21464  518290874300514304  ...  Niki Lauda just confirmed to Sky that Alonso w...\n",
            "\n",
            "[21465 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqHUTLtDVpnL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "2d269c81-1052-4ac3-b27b-cfe1e714af19"
      },
      "source": [
        "#convert to lowercase and remove punctuations\n",
        "\n",
        "import string\n",
        "\n",
        "train=pd.read_csv('train.csv')\n",
        "train=train.dropna(axis=0, how='any')\n",
        "\n",
        "\n",
        "def removetext(text):\n",
        "  return ''.join([i if ord(i)<128 else '' for i in text])\n",
        "\n",
        "#train['tweet_text']=train['tweet_text'].apply(removetext)\n",
        "                                              \n",
        "train['tweet_text']=train['tweet_text'].apply(lambda x:x.lower())\n",
        "#print(lower_tweet)\n",
        "\n",
        "#print(string.punctuation)\n",
        "train['tweet_text']=train['tweet_text'].str.translate(str.maketrans('','',string.punctuation))\n",
        "#train\n",
        "#print(clean_text)\n",
        "\n",
        "\n",
        "\n",
        "train['tweet_text']=train['tweet_text'].str.split()\n",
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "#rain['tweet_text']=nltk.word_tokenize(train['tweet_text'])\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "'''nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "train['tweet_text']=train['tweet_text'].apply(lambda x: [item for item in x if item not in stop])'''\n",
        "train\n",
        "\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264183816548130816</td>\n",
              "      <td>positive</td>\n",
              "      <td>[gas, by, my, house, hit, 339, iu2019m, going,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263405084770172928</td>\n",
              "      <td>negative</td>\n",
              "      <td>[theo, walcott, is, still, shitu002c, watch, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262163168678248449</td>\n",
              "      <td>negative</td>\n",
              "      <td>[its, not, that, iu2019m, a, gsp, fanu002c, i,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264249301910310912</td>\n",
              "      <td>negative</td>\n",
              "      <td>[iranian, general, says, israelu2019s, iron, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262682041215234048</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[tehranu002c, mon, amour, obama, tried, to, es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21460</th>\n",
              "      <td>522949024132112384</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[the, day, after, newark, ill, be, able, to, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21461</th>\n",
              "      <td>522372593312350209</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[fec, hold, farewell, session, for, seven, min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21462</th>\n",
              "      <td>522515200592052224</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[luca, di, montezemolo, whos, last, day, was, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21463</th>\n",
              "      <td>523089087155437568</td>\n",
              "      <td>positive</td>\n",
              "      <td>[coffee, is, pretty, much, the, answer, to, al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21464</th>\n",
              "      <td>518290874300514304</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[niki, lauda, just, confirmed, to, sky, that, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21465 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                                         tweet_text\n",
              "0      264183816548130816  ...  [gas, by, my, house, hit, 339, iu2019m, going,...\n",
              "1      263405084770172928  ...  [theo, walcott, is, still, shitu002c, watch, r...\n",
              "2      262163168678248449  ...  [its, not, that, iu2019m, a, gsp, fanu002c, i,...\n",
              "3      264249301910310912  ...  [iranian, general, says, israelu2019s, iron, d...\n",
              "4      262682041215234048  ...  [tehranu002c, mon, amour, obama, tried, to, es...\n",
              "...                   ...  ...                                                ...\n",
              "21460  522949024132112384  ...  [the, day, after, newark, ill, be, able, to, s...\n",
              "21461  522372593312350209  ...  [fec, hold, farewell, session, for, seven, min...\n",
              "21462  522515200592052224  ...  [luca, di, montezemolo, whos, last, day, was, ...\n",
              "21463  523089087155437568  ...  [coffee, is, pretty, much, the, answer, to, al...\n",
              "21464  518290874300514304  ...  [niki, lauda, just, confirmed, to, sky, that, ...\n",
              "\n",
              "[21465 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRynYyCAuP4W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "4e95cdee-d450-4b9a-ad0a-0f1ae13b6dd2"
      },
      "source": [
        "'''import nltk\n",
        "s=train['tweet_text'].iloc[0]\n",
        "#s=s.split()\n",
        "s=list(nltk.bigrams(s))\n",
        "s'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gas', 'by'),\n",
              " ('by', 'my'),\n",
              " ('my', 'house'),\n",
              " ('house', 'hit'),\n",
              " ('hit', '339'),\n",
              " ('339', 'iu2019m'),\n",
              " ('iu2019m', 'going'),\n",
              " ('going', 'to'),\n",
              " ('to', 'chapel'),\n",
              " ('chapel', 'hill'),\n",
              " ('hill', 'on'),\n",
              " ('on', 'sat')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfqZqvuQd_P7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "2c10c85c-d963-453c-b798-a3fc41c25dce"
      },
      "source": [
        "#bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize \n",
        "\n",
        "#token = nltk.word_tokenize(text)\n",
        "'''for i in range(len(train)):\n",
        "    #token = nltk.word_tokenize(line)\n",
        "    train['tweet_text'].iloc[i]= list(nltk.bigrams(train['tweet_text'].iloc[i])) \n",
        "    #bigram = list(ngrams(token, 2))'''\n",
        "\n",
        "\n",
        "'''for i in range(len(train)):\n",
        "  ans=[]\n",
        "  arr = train['tweet_text'].iloc[i]\n",
        "  for j in range(len(arr)-1):\n",
        "    ans.append([[arr[j], arr[j+1]]])\n",
        "\n",
        "  train['tweet_text'].iloc[i]= ans '''\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264183816548130816</td>\n",
              "      <td>positive</td>\n",
              "      <td>[(gas, by), (by, my), (my, house), (house, hit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263405084770172928</td>\n",
              "      <td>negative</td>\n",
              "      <td>[(theo, walcott), (walcott, is), (is, still), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262163168678248449</td>\n",
              "      <td>negative</td>\n",
              "      <td>[(its, not), (not, that), (that, iu2019m), (iu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264249301910310912</td>\n",
              "      <td>negative</td>\n",
              "      <td>[(iranian, general), (general, says), (says, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262682041215234048</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(tehranu002c, mon), (mon, amour), (amour, oba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21460</th>\n",
              "      <td>522949024132112384</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(the, day), (day, after), (after, newark), (n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21461</th>\n",
              "      <td>522372593312350209</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(fec, hold), (hold, farewell), (farewell, ses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21462</th>\n",
              "      <td>522515200592052224</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(luca, di), (di, montezemolo), (montezemolo, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21463</th>\n",
              "      <td>523089087155437568</td>\n",
              "      <td>positive</td>\n",
              "      <td>[(coffee, is), (is, pretty), (pretty, much), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21464</th>\n",
              "      <td>518290874300514304</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(niki, lauda), (lauda, just), (just, confirme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21465 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                                         tweet_text\n",
              "0      264183816548130816  ...  [(gas, by), (by, my), (my, house), (house, hit...\n",
              "1      263405084770172928  ...  [(theo, walcott), (walcott, is), (is, still), ...\n",
              "2      262163168678248449  ...  [(its, not), (not, that), (that, iu2019m), (iu...\n",
              "3      264249301910310912  ...  [(iranian, general), (general, says), (says, i...\n",
              "4      262682041215234048  ...  [(tehranu002c, mon), (mon, amour), (amour, oba...\n",
              "...                   ...  ...                                                ...\n",
              "21460  522949024132112384  ...  [(the, day), (day, after), (after, newark), (n...\n",
              "21461  522372593312350209  ...  [(fec, hold), (hold, farewell), (farewell, ses...\n",
              "21462  522515200592052224  ...  [(luca, di), (di, montezemolo), (montezemolo, ...\n",
              "21463  523089087155437568  ...  [(coffee, is), (is, pretty), (pretty, much), (...\n",
              "21464  518290874300514304  ...  [(niki, lauda), (lauda, just), (just, confirme...\n",
              "\n",
              "[21465 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65FvZjVjHX46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "7644c161-1b82-434d-f1c9-8b7859162363"
      },
      "source": [
        "'''new_data=train.drop('tweet_text',axis=1) \n",
        "new_data.insert(2,\"clean_text\", clean_text)\n",
        "#print(new_data.clean_text)\n",
        "print(new_data['clean_text'])'''\n",
        "\n",
        "#array=train['tweet_text'].str.split(' ', expand=True).stack().value_counts()\n",
        "array=pd.Series([y for x in  train['tweet_text'] for y in x]).value_counts()\n",
        "print(array)\n",
        "d= {'word':array.index, 'frequency': array}\n",
        "#print(d)\n",
        "df2= pd.DataFrame(data= d)\n",
        "\n",
        "#df2['word']=df2['word'][df2['word']!=df2['word'].isnull() or df2['word']!='']\n",
        "df2['frequency']=df2['frequency'][df2['frequency']>9]\n",
        "\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(in, the)             1648\n",
            "(of, the)             1257\n",
            "(for, the)            1137\n",
            "(going, to)           1130\n",
            "(on, the)             1114\n",
            "                      ... \n",
            "(american, except)       1\n",
            "(like, mj)               1\n",
            "(29th, music)            1\n",
            "(too, our)               1\n",
            "(go, starbucks)          1\n",
            "Length: 207657, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(in, the)</th>\n",
              "      <td>(in, the)</td>\n",
              "      <td>1648.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(of, the)</th>\n",
              "      <td>(of, the)</td>\n",
              "      <td>1257.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(for, the)</th>\n",
              "      <td>(for, the)</td>\n",
              "      <td>1137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(going, to)</th>\n",
              "      <td>(going, to)</td>\n",
              "      <td>1130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(on, the)</th>\n",
              "      <td>(on, the)</td>\n",
              "      <td>1114.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(american, except)</th>\n",
              "      <td>(american, except)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like, mj)</th>\n",
              "      <td>(like, mj)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(29th, music)</th>\n",
              "      <td>(29th, music)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(too, our)</th>\n",
              "      <td>(too, our)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(go, starbucks)</th>\n",
              "      <td>(go, starbucks)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>207657 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  word  frequency\n",
              "(in, the)                    (in, the)     1648.0\n",
              "(of, the)                    (of, the)     1257.0\n",
              "(for, the)                  (for, the)     1137.0\n",
              "(going, to)                (going, to)     1130.0\n",
              "(on, the)                    (on, the)     1114.0\n",
              "...                                ...        ...\n",
              "(american, except)  (american, except)        NaN\n",
              "(like, mj)                  (like, mj)        NaN\n",
              "(29th, music)            (29th, music)        NaN\n",
              "(too, our)                  (too, our)        NaN\n",
              "(go, starbucks)        (go, starbucks)        NaN\n",
              "\n",
              "[207657 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQplmlpbHa2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5115f94-109f-4506-e4e6-7e16ddaf683d"
      },
      "source": [
        "'''import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "#token_words=[]\n",
        "#final_words=[]\n",
        "#token_words=new_data.clean_text.apply(word_tokenize)\n",
        "new_data['clean_text']=new_data.clean_text.apply(word_tokenize)\n",
        "print(new_data)\n",
        "\n",
        "\n",
        "#array=new_data['clean_text'].stack().value_counts()\n",
        "#print(array)'''\n",
        "'''d={'word': array.index, 'frequency':array}\n",
        "df2=pd.DataFrame(data=d)\n",
        "\n",
        "df2['frequency']=df2['frequency'][df2['frequency']>10]\n",
        "df2''' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"d={'word': array.index, 'frequency':array}\\ndf2=pd.DataFrame(data=d)\\n\\ndf2['frequency']=df2['frequency'][df2['frequency']>10]\\ndf2\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9feBenn-OQeo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "ba3b6e0e-0510-4bb1-d8e1-9c7d729f37e6"
      },
      "source": [
        "'''array=pd.Series([y for x in  new_data['clean_text'] for y in x]).value_counts()\n",
        "\n",
        "#array=new_data['clean_text'].value_counts()\n",
        "print(array)'''\n",
        "\n",
        "df2=df2.dropna(axis=0, how='any')\n",
        "df2.to_csv('wordbag.csv', header=True, index=False, encoding='utf-8')\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(in, the)</th>\n",
              "      <td>(in, the)</td>\n",
              "      <td>1648.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(of, the)</th>\n",
              "      <td>(of, the)</td>\n",
              "      <td>1257.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(for, the)</th>\n",
              "      <td>(for, the)</td>\n",
              "      <td>1137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(going, to)</th>\n",
              "      <td>(going, to)</td>\n",
              "      <td>1130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(on, the)</th>\n",
              "      <td>(on, the)</td>\n",
              "      <td>1114.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i, be)</th>\n",
              "      <td>(i, be)</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(a, man)</th>\n",
              "      <td>(a, man)</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(and, win)</th>\n",
              "      <td>(and, win)</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(and, how)</th>\n",
              "      <td>(and, how)</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(work, at)</th>\n",
              "      <td>(work, at)</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3926 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    word  frequency\n",
              "(in, the)      (in, the)     1648.0\n",
              "(of, the)      (of, the)     1257.0\n",
              "(for, the)    (for, the)     1137.0\n",
              "(going, to)  (going, to)     1130.0\n",
              "(on, the)      (on, the)     1114.0\n",
              "...                  ...        ...\n",
              "(i, be)          (i, be)       10.0\n",
              "(a, man)        (a, man)       10.0\n",
              "(and, win)    (and, win)       10.0\n",
              "(and, how)    (and, how)       10.0\n",
              "(work, at)    (work, at)       10.0\n",
              "\n",
              "[3926 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGmFEeDsULzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "8adf97ce-98f5-435b-9339-0d735e63edcf"
      },
      "source": [
        "'''from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "final_words= token_words.apply(lambda x: [item for item in x if item not in stop])\n",
        "print(final_words)'''\n",
        "#train['tweet_text']=train['tweet_text'].str.split()\n",
        "train\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264183816548130816</td>\n",
              "      <td>positive</td>\n",
              "      <td>[(gas, by), (by, my), (my, house), (house, hit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263405084770172928</td>\n",
              "      <td>negative</td>\n",
              "      <td>[(theo, walcott), (walcott, is), (is, still), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262163168678248449</td>\n",
              "      <td>negative</td>\n",
              "      <td>[(its, not), (not, that), (that, iu2019m), (iu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264249301910310912</td>\n",
              "      <td>negative</td>\n",
              "      <td>[(iranian, general), (general, says), (says, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262682041215234048</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(tehranu002c, mon), (mon, amour), (amour, oba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21460</th>\n",
              "      <td>522949024132112384</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(the, day), (day, after), (after, newark), (n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21461</th>\n",
              "      <td>522372593312350209</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(fec, hold), (hold, farewell), (farewell, ses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21462</th>\n",
              "      <td>522515200592052224</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(luca, di), (di, montezemolo), (montezemolo, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21463</th>\n",
              "      <td>523089087155437568</td>\n",
              "      <td>positive</td>\n",
              "      <td>[(coffee, is), (is, pretty), (pretty, much), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21464</th>\n",
              "      <td>518290874300514304</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[(niki, lauda), (lauda, just), (just, confirme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21465 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                                         tweet_text\n",
              "0      264183816548130816  ...  [(gas, by), (by, my), (my, house), (house, hit...\n",
              "1      263405084770172928  ...  [(theo, walcott), (walcott, is), (is, still), ...\n",
              "2      262163168678248449  ...  [(its, not), (not, that), (that, iu2019m), (iu...\n",
              "3      264249301910310912  ...  [(iranian, general), (general, says), (says, i...\n",
              "4      262682041215234048  ...  [(tehranu002c, mon), (mon, amour), (amour, oba...\n",
              "...                   ...  ...                                                ...\n",
              "21460  522949024132112384  ...  [(the, day), (day, after), (after, newark), (n...\n",
              "21461  522372593312350209  ...  [(fec, hold), (hold, farewell), (farewell, ses...\n",
              "21462  522515200592052224  ...  [(luca, di), (di, montezemolo), (montezemolo, ...\n",
              "21463  523089087155437568  ...  [(coffee, is), (is, pretty), (pretty, much), (...\n",
              "21464  518290874300514304  ...  [(niki, lauda), (lauda, just), (just, confirme...\n",
              "\n",
              "[21465 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQkRfX-SR8pN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "a0ced2da-c300-48b3-e3de-97f13797e585"
      },
      "source": [
        "wordbag=pd.read_csv('wordbag.csv')\n",
        "wordbag.dropna(axis=0, how='any')\n",
        "wordbag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>('in', 'the')</td>\n",
              "      <td>1648.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>('of', 'the')</td>\n",
              "      <td>1257.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>('for', 'the')</td>\n",
              "      <td>1137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>('going', 'to')</td>\n",
              "      <td>1130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>('on', 'the')</td>\n",
              "      <td>1114.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3921</th>\n",
              "      <td>('i', 'be')</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922</th>\n",
              "      <td>('a', 'man')</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3923</th>\n",
              "      <td>('and', 'win')</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3924</th>\n",
              "      <td>('and', 'how')</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925</th>\n",
              "      <td>('work', 'at')</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3926 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 word  frequency\n",
              "0       ('in', 'the')     1648.0\n",
              "1       ('of', 'the')     1257.0\n",
              "2      ('for', 'the')     1137.0\n",
              "3     ('going', 'to')     1130.0\n",
              "4       ('on', 'the')     1114.0\n",
              "...               ...        ...\n",
              "3921      ('i', 'be')       10.0\n",
              "3922     ('a', 'man')       10.0\n",
              "3923   ('and', 'win')       10.0\n",
              "3924   ('and', 'how')       10.0\n",
              "3925   ('work', 'at')       10.0\n",
              "\n",
              "[3926 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVjqXh-xhCcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "d521a4c4-b3ee-4afd-d8c0-558c0756bc0f"
      },
      "source": [
        "#new_data=new_data.drop('clean_text',axis=1) \n",
        "#new_data.insert(2,\"final_words\", final_words)\n",
        "#print(new_data.clean_text)\n",
        "#print(new_data.final_words)\n",
        "\n",
        "#new_data['clean_text']=new_data['clean_text'].str.split() \n",
        "#new_data.insert(2,\"final_words\", final_words)\n",
        "#print(new_data.clean_text)\n",
        "#new_data.to_csv('new_data.csv')\n",
        "#new_data=pd.read_csv('new_data.csv')\n",
        "\n",
        "#new_data=new_data.drop('Unnamed: 0',axis=1)\n",
        "print(train.sentiment)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        positive\n",
            "1        negative\n",
            "2        negative\n",
            "3        negative\n",
            "4         neutral\n",
            "           ...   \n",
            "21460     neutral\n",
            "21461     neutral\n",
            "21462     neutral\n",
            "21463    positive\n",
            "21464     neutral\n",
            "Name: sentiment, Length: 21465, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_65YsGQY7ON"
      },
      "source": [
        "'''import pandas as pd\n",
        "#import collections\n",
        "#array=new_data['final_words'].value_counts()\n",
        "#array=collections.Counter([y for x in new_data['final_words'] for y in x])\n",
        "array=pd.Series([y for x in  new_data['final_words'] for y in x]).value_counts()\n",
        "#print(array)\n",
        "\n",
        "d= {\"word\": array.index, \"frequency\": array}\n",
        "df2=pd.DataFrame(data=d)\n",
        "\n",
        "\n",
        "df2['frequency']=df2['frequency'][df2['frequency']>10]\n",
        "df2=df2.dropna(how='any')\n",
        "\n",
        "df2.to_csv('wordbag.csv',header=True, index= False, encoding='utf-8')\n",
        "wordbag=pd.read_csv('wordbag.csv')\n",
        "print(df2)'''\n",
        "\n",
        "\n",
        "'''from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "final_words= new_data['clean_text'].apply(lambda x: [item for item in x if item not in stop])\n",
        "print(final_words)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLLuUtAnZHKV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf62e827-d5c5-4757-d264-0241f0c0301d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#train,val=train_test_split(new_data, test_size=0.2)\n",
        "\n",
        "#print(train.sentiment)\n",
        "train_positive= train[train['sentiment']== 'positive']\n",
        "train_neutral= train[train['sentiment']== 'neutral']\n",
        "train_negative= train[train['sentiment']== 'negative']\n",
        "#print(train_positive.sentiment, train_positive.tweet_text)\n",
        "\n",
        "positive_instance= len(train_positive)\n",
        "negative_instance= len(train_negative)\n",
        "neutral_instance= len(train_neutral)\n",
        "print(positive_instance, negative_instance, neutral_instance)\n",
        "\n",
        "#frequency['word']=wordbag['word']\n",
        "word_bank=[0]*len(wordbag)\n",
        "positive=[0]*len(wordbag)\n",
        "negative=[0]*len(wordbag)\n",
        "neutral=[0]*len(wordbag)\n",
        "\n",
        "#print(wordbag)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9064 3387 9014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnka0QDtqkZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "996ea9be-3499-40e7-f1fe-9b7ba40f1869"
      },
      "source": [
        "'''pos=[0]*len(train_positive)\n",
        "for i in range(25):\n",
        "  word= wordbag['word'].iloc[i]\n",
        "  print(word)\n",
        "  appears=0\n",
        "  count=0\n",
        "  for j in range(len(train_positive)):\n",
        "    if word in train_positive['tweet_text'].iloc[j]:\n",
        "      appears=1\n",
        "    if appears>0:\n",
        "        count+=1\n",
        "  pos[i]=count'''\n",
        "#print(pos)\n",
        "  \n",
        "x=wordbag['word'].iloc[1]\n",
        "e=eval(x)\n",
        "print(type(e))\n",
        "arr=train_positive['tweet_text'].iloc[j][0]\n",
        "print(type(arr))\n",
        "\n",
        "if x in arr:\n",
        "  print(True)\n",
        "else:\n",
        "  print(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "<class 'tuple'>\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ljbS7wllrq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80bc7757-5d20-4820-b6fc-6eee83438669"
      },
      "source": [
        "for i in range(len(wordbag)):\n",
        "#for i in range(25):\n",
        "  word= eval(wordbag['word'].iloc[i])\n",
        "  \n",
        "  word_bank[i]= word\n",
        "  #print(word)\n",
        "  #check= str(\"'\") + word + str(\"'\")\n",
        "  \n",
        "  count=0\n",
        "  appears=0\n",
        "  for j in range(len(train_positive)):\n",
        "    #appears= train_positive['tweet_text'].iloc[j].count(check)\n",
        "    #appears= train_positive['tweet_text'].iloc[j].count(word)\n",
        "    appears=0\n",
        "    if word in train_positive['tweet_text'].iloc[j]:\n",
        "      #print(train_positive['tweet_text'].iloc[j])\n",
        "      appears=1\n",
        "\n",
        "    if appears>0:\n",
        "      count+=1\n",
        "  positive[i]=count\n",
        "\n",
        "  count=0\n",
        "  appears=0\n",
        "  for k in range(len(train_negative)):\n",
        "    #appears= train_negative['tweet_text'].iloc[k].count(check)\n",
        "    #appears= train_negative['tweet_text'].iloc[k].count(word)\n",
        "\n",
        "    appears=0\n",
        "    if word in train_negative['tweet_text'].iloc[k]:\n",
        "      appears=1\n",
        "\n",
        "    if appears>0:\n",
        "      count+=1\n",
        "  negative[i]=count\n",
        "\n",
        "  count=0\n",
        "  appears=0\n",
        "  for l in range(len(train_neutral)):\n",
        "    #appears= train_neutral['tweet_text'].iloc[l].count(check)\n",
        "    #appears= train_neutral['tweet_text'].iloc[l].count(word)\n",
        "\n",
        "    appears=0\n",
        "    if word in train_neutral['tweet_text'].iloc[l]:\n",
        "      appears=1\n",
        "\n",
        "\n",
        "    if appears>0:\n",
        "      count+=1\n",
        "  neutral[i]=count\n",
        "\n",
        "  print(i)\n",
        "#print(positive, negative, neutral)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-8e913b2cf44c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mappears\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mappears\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mpositive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bT-IS93VBdQ"
      },
      "source": [
        "d={'word': word_bank, 'positive': positive, 'neutral': neutral, 'negative': negative}\n",
        "freqtable=pd.DataFrame(data=d)\n",
        "\n",
        "\n",
        "freqtable.to_csv('freqtablebi5.csv', header=True, index= False, encoding='utf-8')\n",
        "\n",
        "freq=pd.read_csv('freqtablebi5.csv')\n",
        "print(freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh9zvBMuxYPV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e65f9df2-f5ff-4633-8526-4e84d0ea7ac8"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('freqtablebi5.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_62eb60fc-ab0b-4295-8306-6b710f2f3083\", \"freqtablebi5.csv\", 195599)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llJMTpXp-hps"
      },
      "source": [
        "#for bigrams\n",
        "#type(eval(freq['word'][0]))\n",
        "#freq['word']=eval(freq['word'])\n",
        "#freq"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}